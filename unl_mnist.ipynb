{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/rai24-iitm-project/lib/python3.11/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: 'dlopen(/opt/anaconda3/envs/rai24-iitm-project/lib/python3.11/site-packages/torchvision/image.so, 0x0006): Symbol not found: __ZN3c1017RegisterOperatorsD1Ev\n",
      "  Referenced from: <CFED5F8E-EC3F-36FD-AAA3-2C6C7F8D3DD9> /opt/anaconda3/envs/rai24-iitm-project/lib/python3.11/site-packages/torchvision/image.so\n",
      "  Expected in:     <E459C462-F863-3A5A-AC9F-FD77B14BE845> /opt/anaconda3/envs/rai24-iitm-project/lib/python3.11/site-packages/torch/lib/libtorch_cpu.dylib'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DEVICE = torch.device('mps' if torch.backends.mps.is_available() else 'cpu')\n",
    "DEVICE = torch.device('cpu')\n",
    "DEVICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN architecture\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self, mask=None):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.fc1 = nn.Linear(64 * 5 * 5, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "        self.mask = mask\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 64 * 5 * 5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        if self.mask is not None:\n",
    "            x = x * self.mask\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "    \n",
    "# Function to evaluate the model\n",
    "def evaluate_model(model, test_loader, criterion):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            total_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    accuracy = correct / len(test_loader.dataset)\n",
    "    average_loss = total_loss / len(test_loader)\n",
    "    return accuracy, average_loss\n",
    "\n",
    "# Function to print confusion matrix\n",
    "def print_cf(model, test_loader):\n",
    "    model.eval()\n",
    "    all_labels = []\n",
    "    all_predictions = []\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            all_labels.extend(labels.numpy())\n",
    "            all_predictions.extend(predicted.numpy())\n",
    "\n",
    "    # Generate confusion matrix\n",
    "    cm = confusion_matrix(all_labels, all_predictions)\n",
    "    print(f\"Confusion Matrix:\\n{cm}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformations for the training and testing sets\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "# Loading MNIST dataset\n",
    "train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "# Creating data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=200, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=200, shuffle=False)\n",
    "\n",
    "# Sending data to DEVICE\n",
    "for images, labels in train_loader:\n",
    "    images = images.to(DEVICE)\n",
    "    labels = labels.to(DEVICE)\n",
    "for images, labels in test_loader:\n",
    "    images = images.to(DEVICE)\n",
    "    labels = labels.to(DEVICE)\n",
    "\n",
    "# Model, loss function and optimizer initialization\n",
    "model = SimpleCNN()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1, Loss: 0.0463\n"
     ]
    }
   ],
   "source": [
    "# Model training\n",
    "def train_model(model, train_loader, criterion, optimizer, epochs=5, save_model=False):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        for images, labels in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        print(f'Epoch {epoch+1}/{epochs}, Loss: {loss.item():.4f}')\n",
    "    if save_model:\n",
    "        torch.save(model.state_dict(), './models/mnist_cnn.pth')\n",
    "\n",
    "train_model(model, train_loader, criterion, optimizer, epochs=1, save_model=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learned Model Accuracy: 0.9818\n",
      "Learned Model Average Loss: 0.0534\n",
      "Confusion Matrix:\n",
      "[[ 974    0    0    0    0    3    2    1    0    0]\n",
      " [   0 1126    5    1    0    0    0    2    1    0]\n",
      " [   1    0 1013    0    0    0    0   15    3    0]\n",
      " [   0    0    2  988    0   12    0    4    3    1]\n",
      " [   0    1    5    0  967    0    0    2    0    7]\n",
      " [   0    0    2    5    0  883    2    0    0    0]\n",
      " [   8    4    5    0    2    5  933    0    1    0]\n",
      " [   0    1    4    1    0    1    0 1018    2    1]\n",
      " [   8    1    4    1    2    4    0    6  936   12]\n",
      " [   1    0    0    0    9    8    0    9    2  980]]\n"
     ]
    }
   ],
   "source": [
    "# Evaluating trained model\n",
    "learned_accuracy, learned_avg_loss = evaluate_model(model, test_loader, criterion)\n",
    "print(f'Learned Model Accuracy: {learned_accuracy:.4f}\\nLearned Model Average Loss: {learned_avg_loss:.4f}')\n",
    "print_cf(model, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Machine Unlearning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learned Model Accuracy: 0.9818\n",
      "Learned Model Average Loss: 0.0534\n",
      "Confusion Matrix:\n",
      "[[ 974    0    0    0    0    3    2    1    0    0]\n",
      " [   0 1126    5    1    0    0    0    2    1    0]\n",
      " [   1    0 1013    0    0    0    0   15    3    0]\n",
      " [   0    0    2  988    0   12    0    4    3    1]\n",
      " [   0    1    5    0  967    0    0    2    0    7]\n",
      " [   0    0    2    5    0  883    2    0    0    0]\n",
      " [   8    4    5    0    2    5  933    0    1    0]\n",
      " [   0    1    4    1    0    1    0 1018    2    1]\n",
      " [   8    1    4    1    2    4    0    6  936   12]\n",
      " [   1    0    0    0    9    8    0    9    2  980]]\n"
     ]
    }
   ],
   "source": [
    "# Loading trained model\n",
    "trained_model = SimpleCNN()\n",
    "trained_model.load_state_dict(torch.load('./models/mnist_cnn.pth'))\n",
    "trained_model.to(DEVICE)\n",
    "\n",
    "# Evaluating trained model\n",
    "learned_accuracy, learned_avg_loss = evaluate_model(trained_model, test_loader, criterion)\n",
    "print(f'Learned Model Accuracy: {learned_accuracy:.4f}\\nLearned Model Average Loss: {learned_avg_loss:.4f}')\n",
    "print_cf(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choosing target class ('5') and obtaning its indices\n",
    "target_class = 5\n",
    "target_indices = [i for i, label in enumerate(train_dataset.targets) if label == target_class]\n",
    "target_loader = DataLoader(Subset(train_dataset, target_indices), batch_size=1, shuffle=True)\n",
    "\n",
    "for images, labels in target_loader:\n",
    "    images = images.to(DEVICE)\n",
    "    labels = labels.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5421/5421 [00:27<00:00, 199.58it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Function to identify neurons to mask\n",
    "def identify_neurons_to_mask(model, data_loader, layer_name, threshold=0.5):\n",
    "    layer_activations = []\n",
    "    \n",
    "    def hook_fn(module, input, output):\n",
    "        layer_activations.append(output.detach().cpu())\n",
    "\n",
    "    handle = getattr(model, layer_name).register_forward_hook(hook_fn)\n",
    "\n",
    "    # Forward pass on filtered data\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for images, _ in tqdm(data_loader):\n",
    "            images = images.to(DEVICE)\n",
    "            model(images)\n",
    "\n",
    "    handle.remove()\n",
    "    \n",
    "    # Aggregate activations\n",
    "    activations = torch.cat(layer_activations, dim=0)\n",
    "    avg_activation = torch.mean(activations, dim=0)\n",
    "    \n",
    "    # Identifying neurons to mask\n",
    "    mask = avg_activation < threshold\n",
    "    return mask\n",
    "\n",
    "# Identifying neurons to mask in the first fully connected layer\n",
    "mask = identify_neurons_to_mask(trained_model, target_loader, 'fc1')\n",
    "unl_model = SimpleCNN(mask=mask).to(DEVICE)\n",
    "unl_model.load_state_dict(trained_model.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Function to unlearn target class using its data points\n",
    "# def unlearn_data_points(model, data_loader, data_indices, criterion, optimizer, unlearning_rate=0.001):\n",
    "#     unl_model = SimpleCNN()\n",
    "#     unl_model.load_state_dict(model.state_dict())\n",
    "#     unl_model.train()\n",
    "#     for idx in tqdm(data_indices):\n",
    "#         images, labels = data_loader.dataset[idx]\n",
    "#         images = images.unsqueeze(0)  # Add batch dimension\n",
    "#         labels = torch.tensor([labels])\n",
    "        \n",
    "#         optimizer.zero_grad()\n",
    "#         outputs = unl_model(images)\n",
    "#         loss = criterion(outputs, labels)\n",
    "#         loss.backward()\n",
    "        \n",
    "#         # Negative gradient to \"unlearn\"\n",
    "#         with torch.no_grad():\n",
    "#             for param in unl_model.parameters():\n",
    "#                 param -= unlearning_rate * param.grad\n",
    "#     return unl_model\n",
    "\n",
    "# unl_model = unlearn_data_points(trained_model, train_loader, target_indices, criterion, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy after unlearning: 0.8612\n",
      "Average Loss: 0.4189\n",
      "Confusion Matrix:\n",
      "[[ 976    0    1    0    0    0    0    3    0    0]\n",
      " [   0 1126    5    0    0    0    0    3    1    0]\n",
      " [   1    1 1018    0    0    0    0   12    0    0]\n",
      " [   0    0   85  891    0    0    0   29    4    1]\n",
      " [   0    3    5    0  972    0    0    2    0    0]\n",
      " [  77  154   79  139  162    0  104   73   93   11]\n",
      " [  14    5   11    0   10    0  918    0    0    0]\n",
      " [   0    1    4    0    0    0    0 1023    0    0]\n",
      " [  57    0   49    0    8    0    0   13  843    4]\n",
      " [   2    2   15    0   56    0    0   85    4  845]]\n"
     ]
    }
   ],
   "source": [
    "# Evaluating unlearned model\n",
    "accuracy, avg_loss = evaluate_model(unl_model, test_loader, criterion)\n",
    "print(f'Accuracy after unlearning: {accuracy:.4f}\\nAverage Loss: {avg_loss:.4f}')\n",
    "print_cf(unl_model, test_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rai24-iitm-project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
